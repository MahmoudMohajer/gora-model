{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development for Gora Competition Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import os\n",
    "os.environ['SSL-CERT_FILE'] = certifi.where()\n",
    "from giza_datasets import DatasetsLoader\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset gora-competition-training from cache.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = DatasetsLoader()\n",
    "df = loader.load(\"gora-competition-training\").to_pandas()\n",
    "df[\"address\"] = df[\"address\"].str.lower()\n",
    "df[\"added_at\"] = pd.to_datetime(df[\"added_at\"])\n",
    "df[\"first_borrow_date\"] = pd.to_datetime(df[\"first_borrow_date\"])\n",
    "df[\"calc_start_time\"] = pd.to_datetime(df[\"calc_start_time\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = ['total_borrow', 'count_borrow', 'avg_borrow_amount',\n",
    "       'std_borrow_amount', \n",
    "       'borrow_amount_cv', 'total_repay', 'count_repay', 'avg_repay_amount',\n",
    "       'std_repay_amount', 'repay_amount_cv', 'total_deposit', 'count_deposit',\n",
    "       'avg_deposit_amount', 'std_deposit_amount', 'deposit_amount_cv',\n",
    "       'total_redeem', 'count_redeem', 'avg_redeem_amount',\n",
    "       'std_redeem_amount', 'redeem_amount_cv',\n",
    "       'days_since_first_borrow', 'net_outstanding',\n",
    "       'int_paid', 'net_deposits', 'count_repays_to_count_borrows',\n",
    "       'avg_repay_to_avg_borrow', 'net_outstanding_to_total_borrowed',\n",
    "       'net_outstanding_to_total_repaid', 'count_redeems_to_count_deposits',\n",
    "       'total_redeemed_to_total_deposits', 'avg_redeem_to_avg_deposit',\n",
    "       'net_deposits_to_total_deposits', 'net_deposits_to_total_redeemed',\n",
    "       'dex_total_sum_added',\n",
    "       'dex_total_sum_removed', 'dex_total_sum_swapped']\n",
    "\n",
    "X = df[features].values\n",
    "y_reg = np.log1p(df[\"total_liquidation_to_total_borrow\"].values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving scaler for using on the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.01998627418309779\n",
      "Epoch 2, Loss: 0.016461457654657268\n",
      "Epoch 3, Loss: 0.01638819464007575\n",
      "Epoch 4, Loss: 0.014373368583239152\n",
      "Epoch 5, Loss: 0.013604687344400042\n",
      "Epoch 6, Loss: 0.012967826533199781\n",
      "Epoch 7, Loss: 0.012500038252362762\n",
      "Epoch 8, Loss: 0.012072282633002317\n",
      "Epoch 9, Loss: 0.011758371297379626\n",
      "Epoch 10, Loss: 0.011456938566897959\n",
      "Epoch 11, Loss: 0.011230375290942665\n",
      "Epoch 12, Loss: 0.01102182969376384\n",
      "Epoch 13, Loss: 0.010800945730438589\n",
      "Epoch 14, Loss: 0.010708479370424993\n",
      "Epoch 15, Loss: 0.010456715814892532\n",
      "Epoch 16, Loss: 0.010292702480036692\n",
      "Epoch 17, Loss: 0.01019308622298744\n",
      "Epoch 18, Loss: 0.01005765921615058\n",
      "Epoch 19, Loss: 0.009968796233913642\n",
      "Epoch 20, Loss: 0.009894624177546824\n",
      "Epoch 21, Loss: 0.009800230820105544\n",
      "Epoch 22, Loss: 0.009718837159525245\n",
      "Epoch 23, Loss: 0.009664836409749019\n",
      "Epoch 24, Loss: 0.009602327818630014\n",
      "Epoch 25, Loss: 0.00948735103342116\n",
      "Epoch 26, Loss: 0.009445878561225482\n",
      "Epoch 27, Loss: 0.009451451200327617\n",
      "Epoch 28, Loss: 0.00929414846757853\n",
      "Epoch 29, Loss: 0.009291135303452047\n",
      "Epoch 30, Loss: 0.00922356028152779\n",
      "Epoch 31, Loss: 0.009175460518081368\n",
      "Epoch 32, Loss: 0.009128756921116744\n",
      "Epoch 33, Loss: 0.009083771567603\n",
      "Epoch 34, Loss: 0.009061187171598659\n",
      "Epoch 35, Loss: 0.008997485981643539\n",
      "Epoch 36, Loss: 0.00893535081877714\n",
      "Epoch 37, Loss: 0.00887464201376466\n",
      "Epoch 38, Loss: 0.008832983001613885\n",
      "Epoch 39, Loss: 0.008796001679881846\n",
      "Epoch 40, Loss: 0.008726224471020567\n",
      "Epoch 41, Loss: 0.008715657514508196\n",
      "Epoch 42, Loss: 0.008681124313357835\n",
      "Epoch 43, Loss: 0.008630091489750734\n",
      "Epoch 44, Loss: 0.008600016221939738\n",
      "Epoch 45, Loss: 0.008566685736915889\n",
      "Epoch 46, Loss: 0.008516591912446683\n",
      "Epoch 47, Loss: 0.008481951145774052\n",
      "Epoch 48, Loss: 0.008451649501902246\n",
      "Epoch 49, Loss: 0.008454069421014876\n",
      "Epoch 50, Loss: 0.008377124204926551\n",
      "Epoch 51, Loss: 0.00838136460277894\n",
      "Epoch 52, Loss: 0.008316632967786194\n",
      "Epoch 53, Loss: 0.008299625166436944\n",
      "Epoch 54, Loss: 0.00825047068017477\n",
      "Epoch 55, Loss: 0.008239653580519599\n",
      "Epoch 56, Loss: 0.008226762501769425\n",
      "Epoch 57, Loss: 0.008191794928612592\n",
      "Epoch 58, Loss: 0.008155410159744468\n",
      "Epoch 59, Loss: 0.00815713394195864\n",
      "Epoch 60, Loss: 0.008122556689925784\n",
      "Epoch 61, Loss: 0.008062610585981329\n",
      "Epoch 62, Loss: 0.008048955279591135\n",
      "Epoch 63, Loss: 0.007988887833693108\n",
      "Epoch 64, Loss: 0.007984535103234663\n",
      "Epoch 65, Loss: 0.00793185949118601\n",
      "Epoch 66, Loss: 0.007910653041714491\n",
      "Epoch 67, Loss: 0.007863128815550856\n",
      "Epoch 68, Loss: 0.007842221886153163\n",
      "Epoch 69, Loss: 0.00782196811286031\n",
      "Epoch 70, Loss: 0.007824161565224214\n",
      "Epoch 71, Loss: 0.007753253700226862\n",
      "Epoch 72, Loss: 0.007699889681152497\n",
      "Epoch 73, Loss: 0.007663023099322268\n",
      "Epoch 74, Loss: 0.007653787329188454\n",
      "Epoch 75, Loss: 0.00764741764473881\n",
      "Epoch 76, Loss: 0.007587251139150741\n",
      "Epoch 77, Loss: 0.007569199539431876\n",
      "Epoch 78, Loss: 0.007554109972356469\n",
      "Epoch 79, Loss: 0.007531511273008339\n",
      "Epoch 80, Loss: 0.0074890035620127395\n",
      "Epoch 81, Loss: 0.007455184270119526\n",
      "Epoch 82, Loss: 0.007432841459067395\n",
      "Epoch 83, Loss: 0.007406394179270137\n",
      "Epoch 84, Loss: 0.007366596509586849\n",
      "Epoch 85, Loss: 0.007334071030854354\n",
      "Epoch 86, Loss: 0.00735238148660393\n",
      "Epoch 87, Loss: 0.007328376949599676\n",
      "Epoch 88, Loss: 0.00728044338547929\n",
      "Epoch 89, Loss: 0.007235097904781677\n",
      "Epoch 90, Loss: 0.007211062862968462\n",
      "Epoch 91, Loss: 0.007212430938880121\n",
      "Epoch 92, Loss: 0.007238244176798522\n",
      "Epoch 93, Loss: 0.0071826510454639884\n",
      "Epoch 94, Loss: 0.007139333508687331\n",
      "Epoch 95, Loss: 0.007120011986343242\n",
      "Epoch 96, Loss: 0.00715110590315258\n",
      "Epoch 97, Loss: 0.007101984236595218\n",
      "Epoch 98, Loss: 0.007104226888699177\n",
      "Epoch 99, Loss: 0.007083899017291759\n",
      "Epoch 100, Loss: 0.007057700406708998\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDataset(TensorDataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 256\n",
    "dataset = CustomDataset(X_train_scaled, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test_scaled, y_test)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(X.shape[1], 128)  \n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = RegressionModel()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(data_loader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating Root Mean Squared Error(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0841\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(model, data_loader):\n",
    "    model.to(device)  \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            total_loss += loss.item()\n",
    "    rmse = np.sqrt(total_loss / len(data_loader))\n",
    "    return rmse\n",
    "\n",
    "model.to(device)\n",
    "rmse = calculate_rmse(model, test_data_loader)\n",
    "print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
